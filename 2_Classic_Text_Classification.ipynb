{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will be approaching this project 2 ways. \n",
    "1. Classic text classification, with 1 model predicting 20 newsgroups.\n",
    "2. Tiered text classification, with 1 model predicting 6 topics and then 6 models, each predicting the newsgroups associated with each topic. \n",
    "\n",
    "Below, is the classic text classification.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56) \n",
      "[GCC 7.2.0] \n",
      "\n",
      "Numpy Version: 1.16.4\n",
      "Pandas Version: 0.23.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "libraries = (('Numpy', np), ('Pandas', pd))\n",
    "\n",
    "print(\"Python Version:\", sys.version, '\\n')\n",
    "for lib in libraries:\n",
    "    print('{0} Version: {1}'.format(lib[0], lib[1].__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import TxtFiles as tf\n",
    "import FTCommands as ftc\n",
    "import EvaluatePredictions as ep\n",
    "\n",
    "sys.path.append('../MyModules/')\n",
    "import KleptoFunctions as kf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data\n",
    "Import data from 1_Process_Data.ipynb.  \n",
    "Texts have been cleaned and processed. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: 2019.06.25_cleaned_newsgroups \n",
      "# of Folders: 5 \n",
      "Type: <class 'pandas.core.frame.DataFrame'> \n",
      "Len: 18752\n"
     ]
    }
   ],
   "source": [
    "data = kf.puking_file('2019.06.25_cleaned_newsgroups', data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText Txt files\n",
    "The entire list of doc IDs will be split 3 ways - Training set, Validation Set, & Holdout Set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holdout\t 3751\n",
      "training\t 11250\n",
      "validation\t 3751\n"
     ]
    }
   ],
   "source": [
    "set_ids = tf.training_validation_holdout_split(data['_id'], random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Txt Files\n",
    "Each message is labeled with 1 of 20 newsgroup labels as we are not take the step to predict any of the topics on the Tier1 for the classic model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/holdout_19.txt\n",
      "data/T1_training_19.txt\n",
      "data/T1_validation_19.txt\n"
     ]
    }
   ],
   "source": [
    "for name_part in set_ids.keys():\n",
    "    filepath = data_path+'%s.txt' % name_part\n",
    "    df = data[data['_id'].isin(set_ids[name_part])]\n",
    "    tf.make_txtfile(filepath, df, 'tier2_targets')\n",
    "    print(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = [k for k in set_ids.keys() if 'training' in k][0]+'.txt'\n",
    "train_address = data_path+train_filename\n",
    "test_filename = [k for k in set_ids.keys() if 'validation' in k][0]+'.txt'\n",
    "test_address = data_path+test_filename\n",
    "holdout_filename = [k for k in set_ids.keys() if 'holdout' in k][0]+'.txt'\n",
    "holdout_address = data_path+holdout_filename"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model\n",
    "   * ngram - max length of word ngram.    \n",
    "   * lr - step size to convergance.   \n",
    "   * dim - size of word vectors.   \n",
    "   * ws - size of the context window.  \n",
    "   * epoch - number of passes over the training data.  \n",
    "   * loss - loss function.  \n",
    "       * ns - negative sampling  \n",
    "       * hs - hierarchical softmax  \n",
    "       * softmax  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngram = 3\n",
    "lr = 0.25\n",
    "dim = 200\n",
    "ws = 5\n",
    "epoch = 25\n",
    "loss = 'ns'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t3751\n",
      "P@1\t0.804\n",
      "R@1\t0.804\n",
      "\n",
      "data/T1_model\n",
      "data/T1_prediction_19.txt\n"
     ]
    }
   ],
   "source": [
    "model_address, predict_address = ftc.train_test_predict(train_address, test_address, ngram, lr, dim, ws, epoch, loss)\n",
    "print(model_address)\n",
    "print(predict_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Model\n",
    "Please note: FastText has its own evaluation and it is flawed. It is not precision, recall, accuracy, or f1 score. But it is a reliable measure to determine if a model is improving during a bunch of experiments. However, evaluation with SkLearn is recommended.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t3751\n",
      "P@1\t0.815\n",
      "R@1\t0.815\n",
      "\n",
      "data/holdout_prediction_19.txt\n"
     ]
    }
   ],
   "source": [
    "predict_address = ftc.test_predict(holdout_address, model_address)\n",
    "print(predict_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.8080892948582475\n",
      "recall: 0.805236375031088\n",
      "fscore: 0.8034230052440412\n"
     ]
    }
   ],
   "source": [
    "# how did it do on our holdout set?\n",
    "precision, recall, fscore, support = ep.score_txtfiles(holdout_address, predict_address)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
