{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python Version: 3.6.5 |Anaconda, Inc.| (default, Apr 29 2018, 16:14:56) \n",
      "[GCC 7.2.0] \n",
      "\n",
      "Numpy Version: 1.16.4\n",
      "Pandas Version: 0.23.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "libraries = (('Numpy', np), ('Pandas', pd))\n",
    "\n",
    "print(\"Python Version:\", sys.version, '\\n')\n",
    "for lib in libraries:\n",
    "    print('{0} Version: {1}'.format(lib[0], lib[1].__version__))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import txtFiles as tf\n",
    "import ftCommands as ftc\n",
    "import evaluatePredictions as ep\n",
    "\n",
    "sys.path.append('../myModules/')\n",
    "import kleptoFunctions as kf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = 'data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: 2019.06.25_cleaned_newsgroups \n",
      "# of Folders: 5 \n",
      "Type: <class 'pandas.core.frame.DataFrame'> \n",
      "Len: 18752\n"
     ]
    }
   ],
   "source": [
    "data = kf.puking_file('2019.06.25_cleaned_newsgroups', data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'rec': 3, 'comp': 1, 'talk': 6, 'sci': 4, 'soc': 5}\n"
     ]
    }
   ],
   "source": [
    "tier1_targets = dict(zip(data['tier1_label'], data['tier1_targets']))\n",
    "del tier1_targets['misc']\n",
    "print(tier1_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FastText Txt files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## split ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_state = 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "holdout\t 4688\n",
      "training\t 10548\n",
      "validation\t 3516\n"
     ]
    }
   ],
   "source": [
    "t1_ids = tf.training_validation_holdout_split(data['_id'], random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** comp ***\n",
      "training\t 2751\n",
      "validation\t 917\n",
      "*** rec ***\n",
      "training\t 2199\n",
      "validation\t 734\n",
      "*** sci ***\n",
      "training\t 2221\n",
      "validation\t 741\n",
      "*** soc ***\n",
      "training\t 1350\n",
      "validation\t 451\n",
      "*** talk ***\n",
      "training\t 1495\n",
      "validation\t 499\n"
     ]
    }
   ],
   "source": [
    "experiment_ids = list(t1_ids[[k for k in t1_ids.keys() if 'training' in k][0]])+\\\n",
    "list(t1_ids[[k for k in t1_ids.keys() if 'validation' in k][0]])\n",
    "t2_ids = tf.tier2_training_validation(data, experiment_ids, \\\n",
    "                                       list(tier1_targets.keys()), \\\n",
    "                                       random_state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## txt Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/holdout_19.txt\n",
      "data/T1_training_19.txt\n",
      "data/T1_validation_19.txt\n"
     ]
    }
   ],
   "source": [
    "for name_part in t1_ids.keys():\n",
    "    filepath = data_path+'%s.txt' % name_part\n",
    "    df = data[data['_id'].isin(t1_ids[name_part])]\n",
    "    tf.make_txtfile(filepath, df, 'tier1_targets')\n",
    "    print(filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/comp_training_19.txt\n",
      "data/comp_validation_19.txt\n",
      "data/rec_training_19.txt\n",
      "data/rec_validation_19.txt\n",
      "data/sci_training_19.txt\n",
      "data/sci_validation_19.txt\n",
      "data/soc_training_19.txt\n",
      "data/soc_validation_19.txt\n",
      "data/talk_training_19.txt\n",
      "data/talk_validation_19.txt\n"
     ]
    }
   ],
   "source": [
    "for name_part in t2_ids.keys():\n",
    "    filepath = data_path+'%s.txt' % name_part\n",
    "    df = data[data['_id'].isin(t2_ids[name_part])]\n",
    "    tf.make_txtfile(filepath, df, 'tier2_targets')\n",
    "    print(filepath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FastText Parameters\n",
    "ngram = '2'\n",
    "lr = '0.5'\n",
    "dim = '200'\n",
    "ws = '5'\n",
    "epoch = '25'\n",
    "loss = 'ns'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tier 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_filename = [k for k in t1_ids.keys() if 'training' in k][0]+'.txt'\n",
    "train_address = data_path+train_filename\n",
    "test_filename = [k for k in t1_ids.keys() if 'validation' in k][0]+'.txt'\n",
    "test_address = data_path+test_filename\n",
    "holdout_filename = [k for k in t1_ids.keys() if 'holdout' in k][0]+'.txt'\n",
    "holdout_address = data_path+holdout_filename"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t3516\n",
      "P@1\t0.902\n",
      "R@1\t0.902\n",
      "\n",
      "data/T1_model\n",
      "data/T1_prediction_19.txt\n"
     ]
    }
   ],
   "source": [
    "model_address, predict_address = ftc.train_test_predict(train_address, test_address, ngram, lr, dim, ws, epoch, loss)\n",
    "print(model_address)\n",
    "print(predict_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.8905375812624793\n",
      "recall: 0.8758823788944\n",
      "fscore: 0.8826725725846437\n",
      "support: [913 166 751 739 460 487]\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore, support = ep.score_txtfiles(test_address, predict_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tier 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** comp ***\n",
      "N\t917\n",
      "P@1\t0.833\n",
      "R@1\t0.833\n",
      "\n",
      "data/comp_model\n",
      "\n",
      "*** rec ***\n",
      "N\t734\n",
      "P@1\t0.931\n",
      "R@1\t0.931\n",
      "\n",
      "data/rec_model\n",
      "\n",
      "*** sci ***\n",
      "N\t741\n",
      "P@1\t0.947\n",
      "R@1\t0.947\n",
      "\n",
      "data/sci_model\n",
      "\n",
      "*** soc ***\n",
      "N\t451\n",
      "P@1\t0.825\n",
      "R@1\t0.825\n",
      "\n",
      "data/soc_model\n",
      "\n",
      "*** talk ***\n",
      "N\t499\n",
      "P@1\t0.902\n",
      "R@1\t0.902\n",
      "\n",
      "data/talk_model\n"
     ]
    }
   ],
   "source": [
    "for label in sorted(tier1_targets.keys()):\n",
    "    train_address = data_path+'%s_training_%s.txt' % (label, str(random_state))\n",
    "    test_address = data_path+'%s_validation_%s.txt' % (label, str(random_state))\n",
    "    \n",
    "    print('\\n***', label, '***')\n",
    "    model_address, predict_address = ftc.train_test_predict(train_address, test_address, ngram, lr, dim, ws, epoch, loss)\n",
    "    print(model_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Holdout set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tier 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_address = data_path+'T1_model'\n",
    "test_address = data_path+'holdout_%s.txt' % str(random_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "N\t4688\n",
      "P@1\t0.917\n",
      "R@1\t0.917\n",
      "\n",
      "data/holdout_prediction_19.txt\n"
     ]
    }
   ],
   "source": [
    "predict_address = ftc.test_predict(test_address, model_address)\n",
    "print(predict_address)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.9062264886158423\n",
      "recall: 0.8951481608099091\n",
      "fscore: 0.9004165917597077\n",
      "support: [1181  244 1034  980  619  630]\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore, support = ep.score_txtfiles(test_address, predict_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update df with Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4688, 7)\n"
     ]
    }
   ],
   "source": [
    "holdout_data = data[data['_id'].isin(t1_ids['holdout_'+str(random_state)])]\n",
    "print(holdout_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4688, 8)\n"
     ]
    }
   ],
   "source": [
    "predict_labels = [int(p[9:]) for p in ep.collect_labels(predict_address)]\n",
    "holdout_data.insert(loc=0, column='tier1_predictions', value=predict_labels)\n",
    "print(holdout_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tier 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tier2 Txt Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t1_name in tier1_targets:\n",
    "    filename = data_path+'holdout_%s.txt' % t1_name\n",
    "    df = holdout_data[holdout_data['tier1_predictions']==tier1_targets[t1_name]]\n",
    "    tf.make_txtfile(filename, df, 'tier2_targets')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** rec ***\n",
      "N\t986\n",
      "P@1\t0.953\n",
      "R@1\t0.953\n",
      "\n",
      "data/holdout_prediction_rec.txt\n",
      "\n",
      "*** comp ***\n",
      "N\t1105\n",
      "P@1\t0.86\n",
      "R@1\t0.86\n",
      "\n",
      "data/holdout_prediction_comp.txt\n",
      "\n",
      "*** talk ***\n",
      "N\t577\n",
      "P@1\t0.939\n",
      "R@1\t0.939\n",
      "\n",
      "data/holdout_prediction_talk.txt\n",
      "\n",
      "*** sci ***\n",
      "N\t884\n",
      "P@1\t0.974\n",
      "R@1\t0.974\n",
      "\n",
      "data/holdout_prediction_sci.txt\n",
      "\n",
      "*** soc ***\n",
      "N\t558\n",
      "P@1\t0.855\n",
      "R@1\t0.855\n",
      "\n",
      "data/holdout_prediction_soc.txt\n"
     ]
    }
   ],
   "source": [
    "for t1_name in tier1_targets:\n",
    "    model_address = data_path+'%s_model' % t1_name\n",
    "    test_address = data_path+'holdout_%s.txt' % t1_name\n",
    "\n",
    "    print('\\n***', t1_name, '***')\n",
    "    predict_address = ftc.test_predict(test_address, model_address)\n",
    "    print(predict_address)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update df with Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** rec ***\n",
      "(1039, 9)\n",
      "*** comp ***\n",
      "(1216, 9)\n",
      "*** talk ***\n",
      "(616, 9)\n",
      "*** sci ***\n",
      "(991, 9)\n",
      "*** soc ***\n",
      "(599, 9)\n"
     ]
    }
   ],
   "source": [
    "tier2_pred_dfs = {}\n",
    "for t1_name in tier1_targets:\n",
    "    print('***', t1_name, '***')\n",
    "    predict_address = data_path+'holdout_prediction_%s.txt' % t1_name   \n",
    "    predict_labels = [int(p[9:]) for p in ep.collect_labels(predict_address)]\n",
    "    df = holdout_data[holdout_data['tier1_predictions']==tier1_targets[t1_name]]\n",
    "    \n",
    "    df.insert(loc=0, column='tier2_predictions', value=predict_labels)\n",
    "    print(df.shape)\n",
    "    tier2_pred_dfs[t1_name] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = holdout_data[holdout_data['tier1_predictions']==2]\n",
    "df.insert(loc=0, column='tier2_predictions', value=21)\n",
    "tier2_pred_dfs['misc'] = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4688, 9)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "holdout_data = pd.concat(tier2_pred_dfs.values())\n",
    "holdout_data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holdout Set Hiearchical Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.8427593764773548\n",
      "recall: 0.8374776844288027\n",
      "fscore: 0.8383926824765956\n",
      "support: [228 274 230 209 240 244 249 258 268 259 245 236 239 260 204 256 159 237\n",
      " 211 182]\n"
     ]
    }
   ],
   "source": [
    "precision, recall, fscore, support = ep.score_columns(holdout_data, 'tier2_targets', 'tier2_predictions')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
